"""
ìë™ ì¬í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (Auto Retrainer - 5M)
ë§¤ì¼ ì‹¤í–‰ë˜ì–´ ìµœì‹  ë°ì´í„°ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
"""
import ccxt
import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
import os
import sys
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

def fetch_and_train():
    try:
        print(f"[{datetime.now()}] ğŸ”„ ì¬í•™ìŠµ ì‹œì‘ (5M)...")
        
        api_key = os.getenv('BINANCE_API_KEY')
        secret = os.getenv('BINANCE_SECRET')
        exchange = ccxt.binance({
            'apiKey': api_key,
            'secret': secret,
            'enableRateLimit': True,
            'options': {'defaultType': 'future'}
        })
        
        csv_path = 'latest_data_5m.csv'
        if os.path.exists(csv_path):
            df_old = pd.read_csv(csv_path)
            if 'datetime' not in df_old.columns:
                 df_old['datetime'] = pd.to_datetime(df_old['timestamp'], unit='ms')
            last_time = df_old['datetime'].max()
            since = int(last_time.timestamp() * 1000)
        else:
            df_old = pd.DataFrame()
            since = exchange.parse8601('2024-01-01T00:00:00Z')

        all_ohlcv = []
        while True:
            ohlcv = exchange.fetch_ohlcv('BTC/USDT', '5m', since=since, limit=1000)
            if not ohlcv: break
            last = ohlcv[-1][0]
            if last == since: break
            since = last + 1
            all_ohlcv.extend(ohlcv)
            print(f"   ë‹¤ìš´ë¡œë“œ ì¤‘... {len(all_ohlcv)}ê±´")
            if len(ohlcv) < 1000: break
            
        if all_ohlcv:
            df_new = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df_new['datetime'] = pd.to_datetime(df_new['timestamp'], unit='ms')
            if not df_old.empty:
                df = pd.concat([df_old, df_new]).drop_duplicates(subset='timestamp').reset_index(drop=True)
            else:
                df = df_new
        else:
            df = df_old
        
        df.to_csv(csv_path, index=False)
        print(f"   ë°ì´í„° ë³‘í•© ì™„ë£Œ: ì´ {len(df)}ê±´")
        
        train_models(df)
        
    except Exception as e:
        print(f"âŒ ì¬í•™ìŠµ ì‹¤íŒ¨: {e}")

def train_models(df):
    # ì „ì²˜ë¦¬ (5M)
    df['ema_20'] = df['close'].ewm(span=20).mean()
    df['ema_60'] = df['close'].ewm(span=60).mean()
    df['ema_200'] = df['close'].ewm(span=200).mean()
    
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # 5ë¶„ë´‰ì€ MACD ë“± ì¶”ê°€ ì§€í‘œ ì—†ì´ ê¸°ë³¸ ì§€í‘œë§Œ ì‚¬ìš©í–ˆì—ˆìœ¼ë‚˜, ê°•í™”ëœ ë¡œì§ì„ ì ìš©í•´ë„ ë¬´ë°©
    # ë‹¤ë§Œ ê¸°ì¡´ ëª¨ë¸ê³¼ í˜¸í™˜ì„±ì„ ìœ„í•´ 5ë¶„ë´‰ì€ ê¸°ì¡´ ë¡œì§(EMA, RSI, ATR) ìœ ì§€ ê¶Œì¥
    
    tr1 = df['high'] - df['low']
    tr2 = abs(df['high'] - df['close'].shift())
    tr3 = abs(df['low'] - df['close'].shift())
    df['atr'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1).rolling(14).mean()
    
    df['dist_ema20'] = (df['close'] - df['ema_20']) / df['ema_20']
    df['dist_ema60'] = (df['close'] - df['ema_60']) / df['ema_60']
    df['dist_ema200'] = (df['close'] - df['ema_200']) / df['ema_200']
    df['rsi_change'] = df['rsi'].diff()
    df['vol_change'] = df['volume'].pct_change()
    
    # 5ë¶„ë´‰ íƒ€ê²Ÿ
    df['future_return'] = df['close'].shift(-4) / df['close'] - 1 # 20ë¶„ í›„
    df = df.replace([np.inf, -np.inf], np.nan).dropna()
    
    feature_cols = ['rsi', 'rsi_change', 'dist_ema20', 'dist_ema60', 'dist_ema200', 'atr', 'vol_change']
    
    def create_data(target_type):
        df_t = df.copy()
        if target_type == 'short':
            df_t['signal'] = (df_t['close'] < df_t['ema_60'])
            df_t['target'] = (df_t['future_return'] < -0.002).astype(int)
            data = df_t[df_t['signal']]
            return data[feature_cols], data['target']
        elif target_type == 'long':
            df_t['signal'] = (df_t['close'] > df_t['ema_60'])
            df_t['target'] = (df_t['future_return'] > 0.002).astype(int)
            data = df_t[df_t['signal']]
            return data[feature_cols], data['target']
        elif target_type == 'regime':
            df_t['target'] = 0
            df_t.loc[(df_t['close'] > df_t['ema_200']) & (df_t['ema_20'] > df_t['ema_60']), 'target'] = 1
            df_t.loc[(df_t['close'] < df_t['ema_200']) & (df_t['ema_20'] < df_t['ema_60']), 'target'] = 2
            return df_t[feature_cols], df_t['target']
            
    print("ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (5M)...")
    X_s, y_s = create_data('short')
    model_s = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.05, random_state=42)
    model_s.fit(X_s, y_s)
    joblib.dump({'model': model_s, 'features': feature_cols}, 'short_model.pkl') # ì´ë¦„ ì£¼ì˜: short_model.pkl
    
    X_l, y_l = create_data('long')
    model_l = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.05, random_state=42)
    model_l.fit(X_l, y_l)
    joblib.dump({'model': model_l, 'features': feature_cols}, 'long_model.pkl')
    
    X_r, y_r = create_data('regime')
    model_r = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.05, num_class=3, objective='multi:softmax', random_state=42)
    model_r.fit(X_r, y_r)
    joblib.dump({'model': model_r, 'features': feature_cols}, 'regime_model.pkl')
    
    print(f"âœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {datetime.now()}")

if __name__ == "__main__":
    fetch_and_train()
